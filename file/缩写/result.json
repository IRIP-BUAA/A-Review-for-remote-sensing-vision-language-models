{
    "SMLFR": "Generative ConvNet Foundation Model With Sparse Modeling and Low-Frequency Reconstruction for Remote Sensing Image Interpretation",
    "MMEarth": "MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning",
    "SkySense": "Skysense: A multi-modal remote sensing foundation model towards universal interpretation for earth observation imagery",
    "Prithvi": "Foundation models for generalist geospatial artificial intelligence",
    "Presto": "Lightweight, pre-trained transformers for remote sensing timeseries",
    "EarthPT": "EarthPT: a time series foundation model for Earth Observation",
    "USat": "USat: A unified self-supervised encoder for multi-sensor satellite imagery",
    "OFA-Net": "One for all: Toward unified foundation models for earth vision",
    "DOFA": "Neural plasticity-inspired foundation model for observing the Earth crossing modalities",
    "RSPrompter": "RSPrompter: Learning to prompt for remote sensing instance segmentation based on visual foundation model",
    "LeMeViT": "LeMeViT: efficient vision transformer with learnable meta tokens for remote sensing image interpretation",
    "HyperSIGMA": "HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model",
    "U-BARN": "Self-Supervised Spatio-Temporal Representation Learning of Satellite Image Time Series",
    "RingMo-lite": "RingMo-lite: A remote sensing multi-task lightweight network with CNN-transformer hybrid framework",
    "RemoteCLIP": "Remoteclip: A vision language foundation model for remote sensing",
    "Skyscript": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing",
    "GeoRSCLIP": "RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing",
    "S-CLIP": "S-clip: Semi-supervised vision-language learning using few specialist captions",
    "RS-CLIP": "RS-CLIP: Zero shot remote sensing scene classification via contrastive vision-language supervision",
    "GeoCLIP": "Geoclip: Clip-inspired alignment between locations and images for effective worldwide geo-localization",
    "SatCLIP": "Satclip: Global, general-purpose location embeddings with satellite imagery",
    "AddressCLIP": "Addressclip: Empowering vision-language models for city-wide image address localization",
    "StreetCLIP": "Learning generalized zero-shot learners for open-domain image geolocalization",
    "GeoCLAP": "Learning Tri-modal Embeddings for Zero-Shot Soundscape Mapping",
    "RSDiff": "Rsdiff: Remote sensing image generation from text using diffusion model",
    "DiffusionSat": "Diffusionsat: A generative foundation model for satellite imagery",
    "CRS-Diff": "Crs-diff: Controllable generative remote sensing foundation model",
    "MetaEarth": "Metaearth: A generative foundation model for global-scale remote sensing image generation",
    "LHRS-Bot": "Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model",
    "H2RSVLM": "H2RSVLM: Towards Helpful and Honest Remote Sensing Large Vision Language Model",
    "Geochat": "Geochat: Grounded large vision-language model for remote sensing",
    "Skysensegpt": "Skysensegpt: A fine-grained instruction tuning dataset and model for remote sensing vision-language understanding",
    "RSGPT": "Rsgpt: A remote sensing vision language model and benchmark",
    "SkyEyeGPT": "Skyeyegpt: Unifying remote sensing vision-language tasks via instruction tuning with large language model",
    "EarthGPT": "Earthgpt: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain",
    "Popeye": "Popeye: A unified visual-language model for multi-source ship detection from remote sensing imagery",
    "RS-CapRet": "Large language models for captioning and retrieving remote sensing images",
    "RS-LLaVA": "Rs-llava: A large vision-language model for joint captioning and question answering in remote sensing imagery",
    "Tree-GPT": "Tree-GPT: Modular Large Language Model Expert System for Forest Remote Sensing Image Understanding and Interactive Analysis",
    "ChatGPT": "Remote sensing chatgpt: Solving remote sensing tasks with chatgpt and visual models",
    "Change-Agent": "Change-agent: Towards interactive comprehensive remote sensing change interpretation and analysis",
    "RS-Agent": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "CMC-RSSR": "Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding",
    "DINO-MC": "Extending Global-local View Alignment for Self-supervised Learning with Remote Sensing Imagery",
    "CACo": "Change-Aware Sampling and Contrastive Learning for Satellite Images",
    "GASSL": "Geography-Aware Self-Supervised Learning",
    "SeCo": "Seasonal Contrast: Unsupervised Pre-Training From Uncurated Remote Sensing Data",
    "MATTER": "Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks",
    "SSLTransformerRS": "Self-Supervised Vision Transformers for Land-Cover Segmentation and Classification",
    "DINO-MM": "Self-supervised vision transformers for joint SAR-optical representation learning",
    "RSBYOL": "Self-Supervised Learning for Invariant Representations From Multi-Spectral and SAR Images",
    "IaI-SimCLR": "Multi-Modal Multi-Objective Contrastive Learning for Sentinel-1/2 Imagery",
    "DeCUR": "DeCUR: decoupling common \\& unique representations for multimodal self-supervision",
    "Scale-MAE": "2023 IEEE/CVF International Conference on Computer Vision",
    "SAR-JEPA": "Predicting gradient is better: Exploring self-supervised learning for SAR ATR with a joint-embedding predictive architecture",
    "SatMAE": "未找到对应条目",
    "RingMo": "RingMo: A Remote Sensing Foundation Model With Masked Image Modeling",
    "RingMo-Sense": "RingMo-Sense: Remote Sensing Foundation Model for Spatiotemporal Prediction via Spatiotemporal Evolution Disentangling",
    "CtxMIM": "CtxMIM: Context-enhanced masked image modeling for remote sensing image understanding",
    "S2MAE": "S2MAE: A Spatial-Spectral Pretraining Foundation Model for Spectral Remote Sensing Data",
    "SpectralGPT": "SpectralGPT: Spectral Remote Sensing Foundation Model",
    "FG-MAE": "Feature guided masked autoencoder for self-supervised learning in remote sensing",
    "msGFM": "Bridging remote sensors with multisensor geospatial foundation models",
    "A2-MAE": "A2-MAE: A spatial-temporal-spectral unified remote sensing pre-training method based on anchor-aware masked autoencoder",
    "CMID": "CMID: A Unified Self-Supervised Learning Framework for Remote Sensing Image Understanding",
    "MAE": "Cross-Scale MAE: A tale of multiscale exploitation in remote sensing",
    "CROMA": "CROMA: remote sensing representations with contrastive radar-optical masked autoencoders",
    "MSFE": "IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium",
    "GeoKR": "Geographical Knowledge-Driven Representation Learning for Remote Sensing Images",
    "GeCo": "Geographical Supervision Correction for Remote Sensing Representation Learning",
    "MTP": "MTP: Advancing remote sensing foundation model via multi-task pretraining",
    "GeRSP": "Generic Knowledge Boosted Pretraining for Remote Sensing Images",
    "TOV": "TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-Supervised Learning",
    "SoftCon": "Multi-label Guided Soft Contrastive Learning for Efficient Earth Observation Pretraining",
    "SwiMDiff": "SwiMDiff: Scene-Wide Matching Contrastive Learning With Diffusion Constraint for Remote Sensing Image",
    "CSPT": "Consecutive pre-training: A knowledge transfer learning strategy with relevant unlabeled data for remote sensing domain",
    "GFM": "Towards Geospatial Foundation Models via Continual Pretraining",
    "SARATR-X": "SARATR-X: A foundation model for synthetic aperture radar images target recognition",
    "Seco": "Seasonal Contrast: Unsupervised Pre-Training From Uncurated Remote Sensing Data",
    "Levir-KR": "Geographical Knowledge-Driven Representation Learning for Remote Sensing Images",
    "GeoSense": "Generative ConvNet Foundation Model With Sparse Modeling and Low-Frequency Reconstruction for Remote Sensing Image Interpretation",
    "TOV-RS": "TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-Supervised Learning",
    "MillionAID": "On creating benchmark dataset for aerial image interpretation: Reviews, guidances, and million-aid",
    "SAMRS": "Samrs: Scaling-up remote sensing segmentation dataset with segment anything model",
    "Sen12MS": "SEN12MS--A curated dataset of georeferenced multi-spectral sentinel-1/2 imagery for deep learning and data fusion",
    "BigEarthNet-MM": "BigEarthNet-MM: A large-scale, multimodal, multilabel benchmark archive for remote sensing image classification and retrieval [software and data sets]",
    "SSL4EO": "SSL4EO-S12: A large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation [Software and Data Sets]",
    "SatlasPretrain": "Satlaspretrain: A large-scale dataset for remote sensing image understanding",
    "fMoW": "Functional map of the world",
    "fMoW-S2": "未找到对应条目",
    "BigEarthNet-S2": "Bigearthnet: A large-scale benchmark archive for remote sensing image understanding",
    "MSAR": "Large-scale multi-class SAR image target detection dataset-1.0",
    "SAR-Ship": "SAR target recognition based on cross-domain and cross-task transfer learning",
    "SARSim": "未找到对应条目",
    "SAMPLE": "A SAR dataset for ATR development: the Synthetic and Measured Paired Labeled Experiment (SAMPLE)",
    "UCM-Caption": "Deep semantic understanding of high resolution remote sensing image",
    "RSICD": "Exploring models and data for remote sensing image caption generation",
    "RSITMD": "Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval",
    "DOTA": "DOTA: A large-scale dataset for object detection in aerial images",
    "DIOR": "Object detection in optical remote sensing images: A survey and a new benchmark",
    "UCM": "Bag-of-visual-words and spatial extensions for land-use classification",
    "NWPU-RESISC45": "Remote sensing image scene classification: Benchmark and state of the art",
    "SkyScript": "Skyscript: A large and semantically diverse vision-language dataset for remote sensing",
    "RS5M": "RS5M and GeoRSCLIP: A large scale vision-language dataset and a large vision-language model for remote sensing",
    "Sydney-Caption": "Deep semantic understanding of high resolution remote sensing image",
    "NWPU-Caption": "NWPU-captions dataset and MLCA-net for remote sensing image captioning",
    "RSVQA-LR": "RSVQA: Visual question answering for remote sensing data",
    "RSVQA-HR": "RSVQA: Visual question answering for remote sensing data",
    "RSIVQA": "Mutual attention inception network for remote sensing visual question answering",
    "FloodNet": "Floodnet: A high resolution aerial imagery dataset for post flood scene understanding",
    "FAIR1M": "FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery",
    "RSVG": "Visual grounding in remote sensing images",
    "DIOR-RSVG": "Rsvg: Exploring data and models for visual grounding on remote sensing data",
    "RSICap": "Rsgpt: A remote sensing vision language model and benchmark",
    "LHRS-Align": "Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model",
    "LHRS-Instruct": "Lhrs-bot: Empowering remote sensing with vgi-enhanced large multimodal language model",
    "EuroSAT": "Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification",
    "AID": "isaid: A large-scale dataset for instance segmentation in aerial images",
    "Xview": "xview: Objects in context in overhead imagery",
    "DIOR-R": "Anchor-free oriented proposal generator for object detection",
    "SpaceNetv1": "Spacenet: A remote sensing dataset and challenge series",
    "LoveDA": "LoveDA: A remote sensing land-cover dataset for domain adaptive semantic segmentation",
    "iSAID": "isaid: A large-scale dataset for instance segmentation in aerial images",
    "-S2": "Dynamicearthnet: Daily multi-spectral satellite dataset for semantic change segmentation",
    "OSCD": "Urban change detection for multispectral earth observation using convolutional neural networks",
    "LEVIR": "A spatial-temporal attention-based method and a new dataset for remote sensing image change detection",
    "WHU-RS19": "Satellite image classification via two-layer sparse coding with biased image representation",
    "SIRI-WHU": "Dirichlet-derived multiple topic scene classification model for high spatial resolution remote sensing imagery",
    "NWPU-Captions": "NWPU-captions dataset and MLCA-net for remote sensing image captioning",
    "RSVQA": "RSVQA: Visual question answering for remote sensing data"
}