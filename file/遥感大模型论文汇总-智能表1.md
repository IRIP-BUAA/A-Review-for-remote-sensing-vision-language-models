<table style="width:100%;">
<tr>
<td>Paper</td>
<td>key</td>
<td>value</td>
<td>Short Summary</td>
</tr>
  <tr>
    <td rowspan='9' style='text-align: left; width:30%;'><a href='https://arxiv.org/abs/2401.09712'>SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction Tuning with Large Language Model</a></td>
    <td style='text-align: left; width:10%;'>Tag</td>
    <td style='text-align: left; width:20%;'>MLLM</td>
    <td rowspan='9' style='text-align: left; width:40%;word-wrap: break-word;'>1.遥感领域的视觉语言指令数据集（SkyEye968k），包括单任务和多任务对话指令，包括968k条样本的指令跟随数据集2. 提出SkyEyeGPT模型，通过一个对齐层将RS视觉特征投影到语言领域后，它们与任务特定的指令一起被馈送到基于LLM的RS解码器中；设计了一个两阶段微调方法，第一阶段是遥感图文对齐，第二阶段是多任务对话微调</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Visual Encoder</td>
    <td style='text-align: left;'>Transformer</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Text Encoder</td>
    <td style='text-align: left;'>Transformer</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Model Details</td>
    <td style='text-align: left;'>Vision Encoder：EVA-CLIPText Encoder：LLaMA2-chat</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Task</td>
    <td style='text-align: left;'>Image Caption, Visual Grounding, RS VQA</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Code/Project</td>
    <td style='text-align: left;'>https://github.com/ZhanYang-nwpu/SkyEyeGPT</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Survey Inclusion</td>
    <td style='text-align: left;'>nan</td>
  </tr>
  <tr>
    <td style='text-align: left;'>备注</td>
    <td style='text-align: left;'>nan</td>
  </tr>
  <tr>
    <td style='text-align: left;'>Published in</td>
    <td style='text-align: left;'>Arxiv 2024</td>
  </tr>
  </table>