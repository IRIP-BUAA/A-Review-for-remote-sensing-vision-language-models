# A-Review-for-remote-sensing-vision-language-models
This is a repository for ...
## Overleaf
https://www.overleaf.com/5469324254jsdvcqwcsmzz#0edfd1

## Table of Contents
- [A-Review-for-remote-sensing-vision-language-models](#a-review-for-remote-sensing-vision-language-models)
  - [Table of Contents](#table-of-contents)
- [Types of Remote Sensing Vision Language Models](#types-of-remote-sensing-vision-language-models)
- [Applications](#applications)
  - [Pretraining](#pretraining)
- [Dataset](#dataset)
  - [Image Captioning Dataset](#image-captioning-dataset)

# Types of Remote Sensing Vision Language Models
| Paper                                             |  Published in | Code/Project|                                  
|---------------------------------------------------|:-------------:|:------------:|
[example paper](https://arxiv.org/abs/...)|arxuv 2023|-|

# Applications
## Pretraining
| Paper                                             |  Published in | Code/Project|                                  
|---------------------------------------------------|:-------------:|:------------:|
[S-CLIP: Semi-supervised Vision-Language Pre-training using Few Specialist Captions](https://arxiv.org/abs/2305.14095)|arxiv 2023|[code](https://github.com/alinlab/s-clip)
[RemoteCLIP: A Vision Language Foundation Model for Remote Sensing](https://arxiv.org/abs/2306.11029)|arxiv 2023|[code](https://github.com/ChenDelong1999/RemoteCLIP)
[RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model](https://arxiv.org/abs/2306.11300)|arxiv 2023|[Project](https://github.com/om-ai-lab/RS5M)


# Dataset
## Image Captioning Dataset
| Dataset                                            |  Home/Github | Download link|                                  
|---------------------------------------------------|:-------------:|:------------:|
[RSICD](https://ieeexplore.ieee.org/abstract/document/8240966)|[Github](https://github.com/201528014227051/RSICD_optimal)|[[BaiduYun]](https://pan.baidu.com/s/1bp71tE3#list/path=%2F)  [[Google Drive]](https://drive.google.com/open?id=0B1jt7lJDEXy3aE90cG9YSl9ScUk)
[Sydney-Captions](https://ieeexplore.ieee.org/abstract/document/7546397)|[Github](https://github.com/201528014227051/RSICD_optimal)|[[BaiduYun]](https://pan.baidu.com/s/1hujEmcG#list/path=%2F)
[UCM-Captions](https://ieeexplore.ieee.org/abstract/document/7546397)|[Github](https://github.com/201528014227051/RSICD_optimal)|[[BaiduYun]](https://pan.baidu.com/s/1mjPToHq#list/path=%2F)
[NWPU-RESISC45](https://ieeexplore.ieee.org/abstract/document/7891544)|[Github](https://gcheng-nwpu.github.io/#Datasets)|[[BaiduYun]](https://pan.baidu.com/s/1mifR6tU#list/path=%2F)  [[OneDrive]](https://1drv.ms/u/s!AmgKYzARBl5ca3HNaHIlzp_IXjs)
[DIOR-Captions](https://ieeexplore.ieee.org/abstract/document/10066217)|-|-
[RS-5M](https://github.com/om-ai-lab/RS5M)|[Github](https://github.com/om-ai-lab/RS5M)|[[HuggingFace]](https://huggingface.co/datasets/Zilun/RS5M/viewer/Zilun--RS5M/train?row=0)
[LEVIR-CC](https://ieeexplore.ieee.org/abstract/document/9934924)|[Github](https://github.com/Chen-Yang-Liu/RSICC)|[Google Drive](https://drive.google.com/drive/folders/1cEv-BXISfWjw1RTzL39uBojH7atjLdCG) |
[SkyScript](https://arxiv.org/abs/2312.12856)|[github](https://github.com/wangzhecheng/SkyScript)|
